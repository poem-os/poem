# KDD Validation Rules
#
# Defines validation rules for KDD (Knowledge-Driven Development) topology health.
# Rules VAL-001 through VAL-006 enforce documentation quality, discoverability,
# and maintainability standards.
#
# Last updated: 2026-02-02 (VAL-004 threshold adjusted)
# Version: 1.0.1

validation_rules:
  version: "1.0.1"
  last_updated: "2026-02-02"
  maintained_by: "Lisa (Librarian)"

rules:
  # VAL-001: Link Health
  - id: "VAL-001"
    name: "Link Health"
    description: "Validate all internal links in KDD documents are not broken"
    trigger: "document_save"
    severity: "error"      # In theory error, but Lisa treats as warning (graceful degradation)
    threshold: 0           # 0 broken links is the target
    scope:
      - "docs/kdd/patterns/"
      - "docs/kdd/learnings/"
      - "docs/kdd/decisions/"
      - "docs/examples/"
      - "docs/stories/" # Story links to knowledge assets

    validation:
      check_type: "link_validation"
      checks:
        - "Check all relative links (../path/file.md) exist"
        - "Check anchor links (#section) exist in target document"
        - "Skip external URLs (http/https) unless validation enabled"
        - "Report broken links with source and target path"

    thresholds:
      healthy: "0 broken links (100% link health)"
      warning: "1-5 broken links (>95% link health)"
      critical: "6+ broken links (<95% link health)"

    evidence:
      source: "SupportSignal git analysis"
      baseline: "30%+ broken links"
      impact: "30% of KDD links broken, causing knowledge discoverability issues"

    remediation:
      actions:
        - "Run validate-kdd-topology task to identify broken links"
        - "Fix relative paths or update cross-references"
        - "Remove links to deleted documents"
        - "Run regenerate-indexes if index links broken"
      automation: "Automated detection via validate-kdd-topology task"

    graceful_degradation:
      enabled: true
      behavior: "Report as warnings, not errors (advisory only)"
      rationale: "Links may break temporarily during refactoring; don't block workflow"

  # VAL-002: Semantic Similarity (Duplicate Detection)
  - id: "VAL-002"
    name: "Semantic Similarity"
    description: "Detect duplicate or highly similar KDD documents"
    trigger: "document_create"
    severity: "warning"
    threshold: 0.70        # 70% keyword similarity triggers warning
    scope:
      - "docs/kdd/patterns/"
      - "docs/kdd/learnings/"
      - "docs/kdd/decisions/"
      - "docs/examples/"

    validation:
      check_type: "keyword_similarity"
      algorithm: "Jaccard similarity (keyword-based, no RAG/embeddings)"
      checks:
        - "Extract keywords from document (title, content, code)"
        - "Compute pairwise similarity for all documents in scope"
        - "Flag pairs with similarity >= 70%"
        - "Suggest consolidation opportunities"

    thresholds:
      healthy: "<30% average duplication"
      warning: "30-50% average duplication"
      critical: ">50% average duplication"

    similarity_levels:
      exact_duplicate: ">=90% similarity (merge recommended)"
      high_overlap: "70-89% similarity (consider merging or cross-linking)"
      partial_overlap: "50-69% similarity (cross-reference suggested)"

    evidence:
      source: "SupportSignal KDD analysis"
      baseline: "80% overlap (worst case, password validation)"
      impact: "Duplicate documentation causes confusion, maintenance burden"

    remediation:
      actions:
        - "Run detect-semantic-duplicates task to find duplicate pairs"
        - "Human review required for consolidation decisions"
        - "Merge exact duplicates (>=90% similarity)"
        - "Cross-link related documents (70-89% similarity)"
        - "Run *consolidate command (requires human approval)"
      automation: "Automated detection, human-approved consolidation"

    graceful_degradation:
      enabled: true
      behavior: "Advisory warnings only, no auto-merge"
      rationale: "Consolidation requires human judgment, not automatable"

  # VAL-003: Directory Limit (Flat Directory Structure)
  - id: "VAL-003"
    name: "Directory Limit"
    description: "Detect directories with too many files (>20 files)"
    trigger: "document_create"
    severity: "warning"
    threshold: 20          # Warn when directory has >20 files
    scope:
      - "docs/kdd/patterns/"
      - "docs/kdd/learnings/"
      - "docs/kdd/decisions/"
      - "docs/examples/"

    validation:
      check_type: "directory_file_count"
      checks:
        - "Count files in each KDD subdirectory"
        - "Flag directories with >20 files"
        - "Suggest subdirectory organization"

    suggested_subdirectories:
      "docs/kdd/learnings/":
        - "deployment/"
        - "debugging/"
        - "testing/"
        - "ai-integration/"
        - "validation/"
      "docs/kdd/patterns/":
        - "backend/"
        - "frontend/"
        - "security/"
        - "performance/"
      "docs/kdd/decisions/":
        - "by-year/2025/"
        - "by-year/2026/"
        - "by-component/"

    thresholds:
      healthy: "All directories <20 files"
      warning: "1-2 directories >20 files"
      critical: "3+ directories >20 files"

    evidence:
      source: "SupportSignal KDD analysis"
      baseline: "27 files in flat learnings/ directory"
      impact: "Flat directories reduce discoverability, increase cognitive load"

    remediation:
      actions:
        - "Run validate-kdd-topology task to identify over-threshold directories"
        - "Run *suggest-structure command for reorganization recommendations"
        - "Create subdirectories and move files manually (human approval)"
        - "Update index.md files after reorganization"
      automation: "Automated detection and suggestions, manual reorganization"

    graceful_degradation:
      enabled: true
      behavior: "Advisory warnings only, no forced reorganization"
      rationale: "Directory structure is subjective, requires human design"

  # VAL-004: Story File Size
  - id: "VAL-004"
    name: "Story File Size"
    description: "Detect story files exceeding 500 lines"
    trigger: "story_completion"
    severity: "error"      # In theory error, but treated as warning
    threshold: 500         # 500 lines per story file (updated 2026-02-02 for BMAD multi-agent reality)
    scope:
      - "docs/stories/"

    validation:
      check_type: "line_count"
      checks:
        - "Count lines in story file"
        - "Flag stories with >500 lines"
        - "Suggest extracting Pre-Curation Findings and QA Results to KDD docs or external files"

    thresholds:
      healthy: "<500 lines"
      warning: "500-700 lines"
      critical: ">700 lines"

    evidence:
      source: "POEM Story 1.12 analysis (2026-01-30)"
      baseline: "851 lines with 6 agents (Bob, James, Tyler, Quinn, Lisa, + bonus work)"
      rationale: "BMAD comprehensive stories are audit trails with multiple agent contributions, naturally larger than minimal stories"
      impact: "Stories are comprehensive records, not minimal docs; 500-line threshold reflects multi-agent reality"

    suffix_pattern:
      description: "External file pattern for story-related content that doesn't belong inline"
      examples:
        - ".story-SAT.md - Story Acceptance Tests (Tyler's testing guide)"
        - ".yml - QA gate files (Quinn's comprehensive review)"
      benefit: "Keeps story file focused while preserving detailed content in linked files"

    remediation:
      actions:
        - "Extract Pre-Curation Findings to KDD learnings with summary+link in story"
        - "Replace comprehensive QA Results with summary+link to gate file"
        - "Move debugging logs to learning documents (link from story)"
        - "Move pattern details to pattern documents (link from story)"
        - "Summary+link approach: Keep 2-3 sentence summary with context + link to full content"
      automation: "Manual extraction via Lisa's *curate command"
      link_guidance: "When replacing content with links, include brief summary explaining what the link contains (helps readers decide if they need to follow it)"

    graceful_degradation:
      enabled: true
      behavior: "Warning during story review, not blocking"
      rationale: "Story size varies based on complexity and agent count; advisory only"

  # VAL-005: Metadata Completeness
  - id: "VAL-005"
    name: "Metadata Completeness"
    description: "Validate KDD documents have required metadata fields (YAML frontmatter OR inline metadata)"
    trigger: "document_create"
    severity: "warning"
    threshold: null        # All required fields must be present
    scope:
      - "docs/kdd/patterns/"
      - "docs/kdd/learnings/"
      - "docs/kdd/decisions/"
      - "docs/examples/"

    validation:
      check_type: "metadata_validation"
      formats:
        frontmatter: "YAML frontmatter block (preferred for new documents)"
        inline: "Inline metadata using bold fields (accepted for existing documents)"
      checks:
        - "Check YAML frontmatter exists OR inline metadata patterns present"
        - "Verify all required fields present (from kdd-taxonomy.yaml or inline equivalents)"
        - "Validate field formats (dates, status values, etc.)"
        - "Flag incomplete or malformed metadata"

    required_fields_by_type:
      pattern:
        - "domain"
        - "topic"
        - "status"
        - "created"
        - "story_reference"
        - "pattern_type"
      learning:
        - "topic"
        - "issue"
        - "created"
        - "story_reference"
        - "category"
        - "severity"
        - "status"
        - "recurrence_count"
      decision:
        - "adr_number"
        - "title"
        - "status"
        - "created"
        - "decision_date"
      example:
        - "title"
        - "purpose"
        - "category"
        - "created"
        - "difficulty"

    # Inline Metadata Pattern Recognition (Option A)
    inline_metadata_patterns:
      description: "Recognize inline metadata using bold field patterns (e.g., **Field**: value)"
      enabled: true
      field_mappings:
        # Common patterns across all document types
        created:
          patterns: ["**Created**:", "**Date**:", "**Pattern Established**:"]
          format: "YYYY-MM-DD or similar date string"
        story_reference:
          patterns: ["**Source**:", "**Source Stories**:", "**Story**:"]
          format: "Story X.Y or 'Stories X.Y, X.Z'"
        status:
          patterns: ["**Status**:"]
          format: "Active | Deprecated | Accepted | Proposed | Resolved | Recurring"
        topic:
          patterns: ["# {title}", "H1 heading"]
          format: "Document title inferred from H1 heading"
        category:
          patterns: ["**Category**:"]
          format: "deployment | debugging | testing | ai-integration | validation"
        # Pattern-specific
        domain:
          patterns: ["**Domain**:"]
          format: "High-level category (can be inferred from topic)"
          optional_inline: true  # Domain often implicit in title
        pattern_type:
          patterns: ["**Pattern Type**:", "**Type**:"]
          format: "Code Pattern | Architectural Pattern | Validation Pattern"
          optional_inline: true  # Can be inferred from content
        # Learning-specific
        issue:
          patterns: ["**Challenge**:", "**Issue**:", "**Problem**:"]
          format: "Brief issue description"
        severity:
          patterns: ["**Impact**:", "**Severity**:"]
          format: "Low | Medium | High | Critical (may be implicit)"
          optional_inline: true  # Can be inferred from Impact description
        recurrence_count:
          patterns: ["**Recurrence Count**:", "**Occurrences**:"]
          format: "Integer count"
          default: 1  # Assume single occurrence if not specified
        # Decision-specific
        adr_number:
          patterns: ["adr-{NNN}-", "# ADR-{NNN}:"]
          format: "Extracted from filename or H1 heading"
        decision_date:
          patterns: ["**Decision Date**:", "**Accepted**:"]
          format: "YYYY-MM-DD"
          fallback: "created"  # Use created date if decision_date missing

      validation_strategy:
        priority: "Check YAML frontmatter first, fall back to inline patterns"
        completeness_calculation: "Field present if EITHER frontmatter OR inline pattern found"
        strict_mode: false  # Don't require both formats (one is sufficient)

    thresholds:
      healthy: "95%+ documents with complete metadata (frontmatter OR inline)"
      warning: "80-94% complete"
      critical: "<80% complete"

    evidence:
      source: "SupportSignal KDD analysis + POEM implementation"
      baseline: "Inconsistent metadata (no formal schema)"
      poem_baseline: "100% inline metadata format (51% completeness with strict YAML-only check)"
      impact: "Missing metadata reduces discoverability, breaks index generation"

    remediation:
      actions:
        - "Run validate-kdd-topology task to identify incomplete metadata"
        - "Update documents with missing fields (YAML frontmatter OR inline patterns)"
        - "Use templates to ensure metadata completeness for new docs"
        - "Inline metadata recognized via field_mappings patterns"
      automation: "Automated detection (dual-format), manual completion"

    graceful_degradation:
      enabled: true
      behavior: "Accept YAML frontmatter OR inline metadata (not both required)"
      fallback_values:
        - "Filename as title if H1 missing"
        - "Created date from file mtime if not specified"
        - "Recurrence count defaults to 1"
        - "Domain/pattern_type inferred from content if missing"
      rationale: "Dual format support maintains human readability while enabling validation"

  # VAL-006: Recurrence Detection (Recurring Issues)
  - id: "VAL-006"
    name: "Recurrence Detection"
    description: "Detect recurring issues in learning documents"
    trigger: "lesson_create"
    severity: "info"       # Informational, not error
    threshold: 0.60        # 60% signature match to detect recurrence
    scope:
      - "docs/kdd/learnings/"

    validation:
      check_type: "signature_matching"
      algorithm: "Keyword-based signature similarity (problem keywords + components + tech)"
      checks:
        - "Extract problem signature from learning documents"
        - "Compute signature similarity for all learning pairs"
        - "Flag pairs with >=60% signature match"
        - "Track recurrence count per issue"
        - "Recommend pattern promotion for 3+ recurrences"

    signature_components:
      - "Error keywords (e.g., 'CORS', '401', 'timeout')"
      - "Affected components (e.g., 'authentication', 'API')"
      - "Technology stack (e.g., 'Node.js', 'React')"
      - "Triggering conditions (e.g., 'on deployment', 'during login')"

    recurrence_thresholds:
      single: "1 occurrence (not recurring yet)"
      monitor: "2 occurrences (watch for third)"
      promote: "3+ occurrences (pattern promotion candidate)"

    evidence:
      source: "SupportSignal KDD analysis"
      baseline: "0% recurrence detection (no tracking)"
      impact: "Recurring issues not detected, patterns not created"

    remediation:
      actions:
        - "Run detect-recurring-issues task to identify recurring problems"
        - "Promote learnings with 3+ recurrences to patterns"
        - "Update Quinn's review checklist with new patterns"
        - "Archive or cross-reference related learning documents"
      automation: "Automated detection, human-approved promotion"

    graceful_degradation:
      enabled: true
      behavior: "Advisory recommendations only, no forced promotion"
      rationale: "Pattern promotion requires team approval and standardization"

# Global Validation Settings
global_settings:
  # Graceful degradation
  graceful_degradation:
    enabled: true
    description: "All validation rules provide warnings/recommendations, not blocking errors"
    rationale: "Documentation quality should improve incrementally, not block workflows"

  # Advisory mode
  advisory_mode:
    enabled: true
    description: "Lisa suggests improvements, does not enforce compliance"
    rationale: "Lisa is librarian (curator), Quinn is enforcer (validator)"

  # Human-in-loop
  human_approval:
    required_for:
      - "Document consolidation (VAL-002)"
      - "Pattern promotion (VAL-006)"
      - "Directory reorganization (VAL-003)"
    description: "Critical decisions require human judgment, not automated"

# Validation Execution
execution:
  # When to run validation
  triggers:
    document_save: ["VAL-001", "VAL-005"]
    document_create: ["VAL-002", "VAL-003", "VAL-005"]
    story_completion: ["VAL-004"]
    lesson_create: ["VAL-006"]
    manual: ["All rules via *validate-topology command"]

  # Validation frequency
  frequency:
    per_story: "VAL-001, VAL-005 (during knowledge curation)"
    per_epic: "VAL-002, VAL-003, VAL-006 (after epic completion)"
    monthly: "All rules (topology health check)"

  # Reporting
  reporting:
    format: "KDD Health Report (health-report-tmpl.md)"
    metrics:
      - "Link health score (VAL-001)"
      - "Duplication rate (VAL-002)"
      - "Directory structure health (VAL-003)"
      - "Story file size compliance (VAL-004)"
      - "Metadata completeness (VAL-005)"
      - "Recurrence detection rate (VAL-006)"

# Integration with Lisa's Commands
lisa_integration:
  # Commands that use validation rules
  commands:
    "*validate-topology": ["VAL-001", "VAL-003", "VAL-005"]
    "*search-similar": ["VAL-002"]
    "*detect-recurrence": ["VAL-006"]
    "*health-dashboard": ["All rules for metrics"]
    "*curate": ["VAL-001", "VAL-005 (post-curation)"]

  # Workflow integration
  workflow_step: "Step 7 (Lisa curation after QA passes)"
  validation_timing: "After knowledge extraction, before workflow end"
