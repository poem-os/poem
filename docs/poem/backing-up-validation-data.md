# Backing Up Validation Data

**Purpose**: Preserve valuable validation artifacts before operations that might delete `dev-workspace/`

**When to backup**: Before major refactors, system migrations, or intentionally deleting dev-workspace

---

## What Needs Backing Up?

### Valuable Data (Generated by Victor Agent)

**These are NOT disposable**:
- `test-reports/` - Epic progress tracking (e.g., `epic-3-cumulative.md`)
- `test-runs/B72/` - Workflow snapshots for regression testing
- `integration-matrix.md` - Capability integration test results
- `feedback-for-bmad.md` - Strategic feedback for story planning
- `b72-video-testing-guide.md` - B72 workflow testing guide

### User Content (If You Created Any)

- `prompts/` - User-created Handlebars templates
- `schemas/` - User-created JSON schemas
- `mock-data/` - User-generated mock data

### Disposable (Don't Need Backup)

- `README.md` - Generated by `dev-setup.sh`
- `config/` - Usually empty
- `workflow-data/` - Workflow execution state (usually empty)

---

## Quick Backup (Automated Script)

```bash
# From project root
./scripts/backup-validation-data.sh
```

**What it does**:
1. Creates timestamped backup in `validation-backups/backup-YYYYMMDD-HHMMSS/`
2. Copies all validation data
3. Preserves directory structure
4. Shows what was backed up

**Output**:
```
üì¶ POEM Validation Data Backup
==============================

üìÅ Backing up validation data to:
   /path/to/poem/validation-backups/backup-20260109-143000

üìã Backing up test reports...
   ‚úÖ test-reports/
üì∏ Backing up workflow snapshots...
   ‚úÖ test-runs/
üîó Backing up integration matrix...
   ‚úÖ integration-matrix.md
üí¨ Backing up feedback log...
   ‚úÖ feedback-for-bmad.md
üìì Backing up B72 testing guide...
   ‚úÖ b72-video-testing-guide.md

‚úÖ Backup complete!
```

---

## Manual Backup

```bash
# Create backup directory
mkdir -p validation-backups/manual-backup-$(date +%Y%m%d)

# Copy validation data
cp -r dev-workspace/test-reports validation-backups/manual-backup-$(date +%Y%m%d)/
cp -r dev-workspace/test-runs validation-backups/manual-backup-$(date +%Y%m%d)/
cp dev-workspace/integration-matrix.md validation-backups/manual-backup-$(date +%Y%m%d)/
cp dev-workspace/feedback-for-bmad.md validation-backups/manual-backup-$(date +%Y%m%d)/
cp dev-workspace/b72-video-testing-guide.md validation-backups/manual-backup-$(date +%Y%m%d)/
```

---

## Restore from Backup

```bash
# List available backups
ls validation-backups/

# Restore specific backup
cp -r validation-backups/backup-YYYYMMDD-HHMMSS/* dev-workspace/

# Verify restoration
ls -la dev-workspace/test-reports/
ls -la dev-workspace/test-runs/B72/
```

---

## When to Backup

### ‚úÖ Backup Before

- **Major refactors** - Restructuring dev-workspace
- **System migrations** - Moving to new machine
- **Intentional deletion** - You want to start fresh but keep history
- **Epic completion** - Archive Epic 3 data before Epic 4
- **Sharing validation results** - Send backup to team member

### ‚ùå No Backup Needed

- **Running dev-setup.sh** - Script preserves existing data
- **Adding new prompts/schemas** - Not destructive
- **Running Victor validation** - Adds data, doesn't delete

---

## Backup Strategy

### Local Development

```bash
# Backup at key milestones
./scripts/backup-validation-data.sh

# Example timeline:
# - End of Epic 3: backup-epic3-complete-20260115
# - Before Epic 4: backup-before-epic4-20260120
# - After major bug: backup-post-nested-arrays-fix-20260122
```

### Team Sharing

```bash
# Create backup
./scripts/backup-validation-data.sh

# Compress for sharing
tar -czf validation-backup-epic3.tar.gz validation-backups/backup-20260109-143000/

# Share via Dropbox/Google Drive/etc.
```

### Long-term Archival

**Important milestones to archive**:
- Epic completion (Epic 3, Epic 4, etc.)
- Major capability additions
- Before/after significant bugs
- Release candidates

**Where to store**:
- Local: `validation-backups/` (gitignored)
- Cloud: Dropbox, Google Drive, S3 (manual upload)
- Team: Shared network drive

---

## Cleanup Old Backups

```bash
# List backups with sizes
du -sh validation-backups/*

# Remove old backups (be careful!)
rm -rf validation-backups/backup-20260101-*

# Keep only recent backups (example: last 30 days)
find validation-backups/ -name "backup-*" -mtime +30 -exec rm -rf {} \;
```

---

## Backup Verification

After backup, verify contents:

```bash
BACKUP_DIR="validation-backups/backup-YYYYMMDD-HHMMSS"

# Check test reports
ls -lh $BACKUP_DIR/test-reports/

# Check snapshots
ls -lh $BACKUP_DIR/test-runs/B72/

# Check matrices and feedback
ls -lh $BACKUP_DIR/*.md
```

**Expected files**:
- `test-reports/epic-3-cumulative.md`
- `test-runs/B72/story-3.1/`, `story-3.2/`, `story-3.3/`, etc.
- `integration-matrix.md`
- `feedback-for-bmad.md`
- `b72-video-testing-guide.md`

---

## Understanding "Transient"

**dev-workspace is "transient" in two ways**:

### 1. Structure is Transient (Disposable)

- **Directories** - Can be recreated by `dev-setup.sh`
- **README.md** - Generated by script
- **Empty folders** - Safe to delete

### 2. Data is Valuable (Not Disposable!)

Once Victor runs, dev-workspace contains:
- ‚úÖ **Real validation results** - Epic progress, test outcomes
- ‚úÖ **Historical snapshots** - Regression comparison data
- ‚úÖ **Strategic insights** - Feedback for future stories

**This data represents HOURS of validation work**. Back it up!

---

## Common Scenarios

### Scenario 1: Clean Slate (New Feature Testing)

```bash
# Backup existing data
./scripts/backup-validation-data.sh

# Optionally clear dev-workspace (if you want fresh start)
rm -rf dev-workspace/test-reports/*
rm -rf dev-workspace/test-runs/B72/story-*

# Setup fresh structure
./scripts/dev-setup.sh

# Start new validation
/poem/agents/victor
*validate
```

### Scenario 2: Sharing Validation Results with Team

```bash
# Backup
./scripts/backup-validation-data.sh

# Compress
tar -czf epic3-validation-results.tar.gz validation-backups/backup-20260109-143000/

# Share the .tar.gz file

# Team member restores:
tar -xzf epic3-validation-results.tar.gz
cp -r backup-20260109-143000/* dev-workspace/
```

### Scenario 3: Migrating to New Machine

```bash
# On old machine:
./scripts/backup-validation-data.sh
tar -czf poem-validation-data.tar.gz validation-backups/

# Copy poem-validation-data.tar.gz to new machine

# On new machine:
git clone poem-os
cd poem
./scripts/dev-setup.sh
tar -xzf poem-validation-data.tar.gz
cp -r validation-backups/backup-*/\* dev-workspace/
```

### Scenario 4: Epic Completion Archive

```bash
# End of Epic 3
./scripts/backup-validation-data.sh
mv validation-backups/backup-20260115-143000 validation-backups/epic3-complete-20260115

# Start Epic 4 with clean snapshots (optional)
rm -rf dev-workspace/test-runs/B72/story-3.*

# Epic 3 data safely archived in validation-backups/epic3-complete-20260115/
```

---

## FAQ

**Q: Will `dev-setup.sh` delete my validation data?**

A: No! The script uses `mkdir -p` (safe) and only regenerates README.md. It preserves existing data.

**Q: When is it safe to delete dev-workspace?**

A: Only when it's empty (new clone) or you've backed up the validation data first.

**Q: What if I accidentally delete dev-workspace?**

A: Restore from your most recent backup in `validation-backups/`. If no backup exists, you've lost the validation history (but documentation in `docs/` is safe).

**Q: Should I commit validation-backups/ to git?**

A: No, it's gitignored. Backups are local only. For team sharing, use compressed archives or cloud storage.

**Q: How much space do backups use?**

A: Typically 5-20 MB per backup, depending on number of snapshots. Clean up old backups periodically.

**Q: Can I backup to a different location?**

A: Yes, modify the `BACKUP_DIR` variable in `scripts/backup-validation-data.sh` or manually copy to your preferred location.

---

## Resources

- **Backup Script**: `scripts/backup-validation-data.sh`
- **Setup Script**: `scripts/dev-setup.sh` (preserves existing data)
- **Workflow Validation Guide**: `docs/guides/workflow-validation-guide.md`

---

**Last Updated**: 2026-01-09
**Status**: Safe to use, no data loss risk with current setup
