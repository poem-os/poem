# Story 3.2 - Acceptance Test Guide

## Quick Summary

**Story**: Implement New Prompt Workflow
**Status**: Review
**Test Focus**: Validating that the `*new` workflow in the Prompt Engineer agent guides users through creating prompts with schemas and mock data.

## Prerequisites

**Before testing, ensure:**

- [ ] Story status is "Review" or "Complete"
- [ ] POEM server is running (`npm run dev` in `packages/poem-app`)
- [ ] You are in a fresh Claude Code conversation (not this one)
- [ ] Working directory is the POEM project root

**Environment Setup:**

- Node.js: 22.x LTS
- POEM Dev Mode: `POEM_DEV=true` (set in `.env`)
- Working directory: `/Users/davidcruwys/dev/ad/poem-os/poem`

**Server Start Command:**

```bash
cd packages/poem-app && npm run dev
```

---

## ü§ñ Terminal Tests (Scriptable)

Tests using command-line tools - copy-paste ready commands.

### Test A: AC1 - Workflow file exists with correct structure

**What to test**: Workflow file exists at correct location with required metadata

**Command**:

```bash
cat packages/poem-core/workflows/new-prompt.yaml | head -40
```

**Expected Output** (key elements):

```yaml
id: new-prompt
name: Create New Prompt
version: "1.0.0"
author: POEM Framework
lastUpdated: "2025-12-31"

description: |
  Guides users through creating a new Handlebars prompt template...
```

**Validation**:

- ‚úÖ File exists at `packages/poem-core/workflows/new-prompt.yaml`
- ‚úÖ Contains `id: new-prompt`
- ‚úÖ Contains `version`, `author`, `lastUpdated` metadata
- ‚úÖ Contains `description` field
- ‚úÖ Contains `steps:` section

**Status**: ‚úÖ Passed

**Notes**: All metadata fields present (id, version, author, lastUpdated, description)

---

### Test B: AC1, AC7 - Workflow has all required steps

**What to test**: Workflow contains all 9 steps with proper structure

**Command**:

```bash
grep -E "^  - id:" packages/poem-core/workflows/new-prompt.yaml
```

**Expected Output**:

```
  - id: gather-purpose
  - id: gather-inputs
  - id: gather-name
  - id: create-template
  - id: generate-schema
  - id: offer-mock-data
  - id: generate-mock
  - id: preview
  - id: complete
```

**Validation**:

- ‚úÖ Contains 9 workflow steps
- ‚úÖ Steps include elicitation (gather-*), action (create-*, generate-*), and output (complete)
- ‚úÖ Steps follow logical sequence

**Status**: ‚úÖ Passed

**Notes**: All 9 steps present: gather-purpose, gather-inputs, gather-name, create-template, generate-schema, offer-mock-data, generate-mock, preview, complete

---

### Test C: AC7 - Elicitation steps have validation

**What to test**: Elicitation steps include validation rules

**Command**:

```bash
grep -A2 "validation:" packages/poem-core/workflows/new-prompt.yaml
```

**Expected Output** (should include):

```yaml
  validation:
    required: true
    minLength: 20
--
  validation:
    required: true
    minFields: 1
--
  validation:
    required: true
    pattern: "^[a-z][a-z0-9-]*[a-z0-9]$"
```

**Validation**:

- ‚úÖ `gather-purpose` has `required: true` and `minLength`
- ‚úÖ `gather-inputs` has `required: true` and `minFields`
- ‚úÖ `gather-name` has `required: true` and `pattern` for kebab-case

**Status**: ‚úÖ Passed

**Notes**: All 3 elicitation steps have validation: minLength:20, minFields:1, pattern for kebab-case

---

### Test D: AC7 - Steps use stores for data flow

**What to test**: Steps use `stores` key to save responses for subsequent steps

**Command**:

```bash
grep "stores:" packages/poem-core/workflows/new-prompt.yaml
```

**Expected Output**:

```
    stores: promptPurpose
    stores: inputFields
    stores: promptName
    stores: createdTemplatePath
    stores: extractedSchema
    stores: mockDataChoice
    stores: mockDataPath
    stores: renderedPreview
```

**Validation**:

- ‚úÖ Key elicitation steps store their responses
- ‚úÖ Action steps store their outputs
- ‚úÖ Store names are descriptive and consistent

**Status**: ‚úÖ Passed

**Notes**: 8 stores defined: promptPurpose, inputFields, promptName, createdTemplatePath, extractedSchema, mockDataChoice, mockDataPath, renderedPreview

---

### Test E: AC5 - Conditional mock data generation

**What to test**: Mock data step has condition based on user choice

**Command**:

```bash
grep -A3 "id: generate-mock" packages/poem-core/workflows/new-prompt.yaml
```

**Expected Output**:

```yaml
  - id: generate-mock
    name: Generate Mock Data
    type: action
    action: create-file
    condition:
      check: mockDataChoice
      matches: "yes|1|y"
```

**Validation**:

- ‚úÖ `generate-mock` step has `condition` block
- ‚úÖ Condition checks `mockDataChoice` from previous step
- ‚úÖ Matches pattern includes "yes", "1", or "y"

**Status**: ‚úÖ Passed

**Notes**: Condition checks mockDataChoice with matches pattern "yes|1|y"

---

## üßë Human Tests (Visual/Manual)

Tests requiring human observation - interactive Claude Code conversation.

> **IMPORTANT**: These tests require starting a **new Claude Code conversation** and activating the Prompt Engineer agent. You cannot test workflows within the current Dev/SAT agent context.

### Test 1: AC2, AC7 - Prompt Purpose Elicitation

**What to test**: Workflow gathers prompt purpose with structured questions

**Steps**:

1. Start a new Claude Code conversation
2. Type: `/poem/agents/penny`
3. After Penny activates, type: `*new`
4. Observe the first elicitation prompt

**Expected Result**:

‚úÖ Penny displays structured questions asking about:
- Primary Goal (what prompt should accomplish)
- Target Model (optional)
- Output Format (text, json, list, markdown)
- Constraints (optional limits)
- Includes example response

**Evidence**:

- Screenshot of elicitation prompt
- Verify format matches workflow definition

**Status**: ‚¨ú Not Tested | ‚úÖ Passed | ‚ùå Failed

**Notes**: _________________

---

### Test 2: AC2, AC7 - Input Requirements Elicitation

**What to test**: Workflow gathers input field definitions with types

**Steps**:

1. Continue from Test 1
2. Respond with sample purpose: "Generate a greeting message for users. Output as text."
3. Observe the second elicitation prompt

**Expected Result**:

‚úÖ Penny asks for input fields with:
- Field name (camelCase format)
- Type (string, number, boolean, array, object)
- Required/Optional designation
- Description
- Includes example format

**Evidence**:

- Screenshot of input fields prompt
- Verify example shows proper format

**Status**: ‚¨ú Not Tested | ‚úÖ Passed | ‚ùå Failed

**Notes**: _________________

---

### Test 3: AC1, AC7 - Prompt Naming with Validation

**What to test**: Workflow collects prompt name with kebab-case validation

**Steps**:

1. Continue from Test 2
2. Respond with: `name (string, required) - The user's name`
3. Observe the third elicitation prompt
4. Try entering an invalid name like "MyPrompt" (PascalCase)
5. Then enter valid name: `generate-greeting`

**Expected Result**:

‚úÖ Penny:
- Asks for kebab-case prompt name
- Shows valid examples (generate-product-description, etc.)
- Mentions 'suggest' option for auto-suggestion
- Validates name follows kebab-case pattern
- Warns if name conflicts with existing prompt

**Evidence**:

- Screenshot of naming prompt
- Note validation behavior for invalid names

**Status**: ‚¨ú Not Tested | ‚úÖ Passed | ‚ùå Failed

**Notes**: _________________

---

### Test 4: AC3 - Template File Creation

**What to test**: Workflow creates .hbs template file in correct location

**Steps**:

1. Continue from Test 3 (after providing valid name)
2. Observe Penny creating the template
3. Check file exists: `ls prompts/generate-greeting.hbs`

**Expected Result**:

‚úÖ Template file created:
- Location: `prompts/generate-greeting.hbs` (dev mode)
- Contains Handlebars placeholders for inputs
- Follows POEM template structure (Context, Input, Task, Output sections)
- Penny confirms file creation with path

**Evidence**:

- Terminal output showing file creation confirmation
- `cat prompts/generate-greeting.hbs` output

**Status**: ‚¨ú Not Tested | ‚úÖ Passed | ‚ùå Failed

**Notes**: _________________

---

### Test 5: AC4 - Schema Generation

**What to test**: Workflow generates JSON schema in correct location

**Steps**:

1. Continue from Test 4
2. Observe Penny generating schema (may call API)
3. Check file exists: `ls schemas/generate-greeting.json`

**Expected Result**:

‚úÖ Schema file created:
- Location: `schemas/generate-greeting.json` (dev mode)
- Valid JSON schema format
- Contains properties matching template placeholders
- Includes `required` array for mandatory fields
- Penny displays schema structure

**Evidence**:

- Terminal output showing schema creation
- `cat schemas/generate-greeting.json` output

**Status**: ‚¨ú Not Tested | ‚úÖ Passed | ‚ùå Failed

**Notes**: _________________

---

### Test 6: AC5 - Mock Data Offering

**What to test**: Workflow offers to generate mock data

**Steps**:

1. Continue from Test 5
2. Observe Penny asking about mock data

**Expected Result**:

‚úÖ Penny asks:
- "Would you like to generate mock data for testing?"
- Explains benefits (test immediately, verify placeholders)
- Provides Yes/No options
- Clear option numbering (1. Yes, 2. No)

**Evidence**:

- Screenshot of mock data offering

**Status**: ‚¨ú Not Tested | ‚úÖ Passed | ‚ùå Failed

**Notes**: _________________

---

### Test 7: AC5 - Mock Data Generation (If Selected)

**What to test**: Workflow generates mock data when user selects "Yes"

**Steps**:

1. Continue from Test 6
2. Respond with: `yes` or `1`
3. Observe Penny generating mock data
4. Check file exists: `ls mock-data/generate-greeting.json`

**Expected Result**:

‚úÖ Mock data file created:
- Location: `mock-data/generate-greeting.json` (dev mode)
- Contains sample values matching schema types
- `name` field has realistic sample (e.g., "Jane Smith")
- Valid JSON format

**Evidence**:

- Terminal output showing mock data creation
- `cat mock-data/generate-greeting.json` output

**Status**: ‚¨ú Not Tested | ‚úÖ Passed | ‚ùå Failed

**Notes**: _________________

---

### Test 8: AC6 - Preview Rendered Template

**What to test**: Workflow shows preview of rendered template with data

**Steps**:

1. Continue from Test 7
2. Observe Penny rendering preview

**Expected Result**:

‚úÖ Penny displays:
- Rendered template output (placeholders replaced with mock/example data)
- Render time in milliseconds
- Any warnings (missing fields, etc.)
- Offers option to refine if unsatisfactory

**Evidence**:

- Screenshot of rendered preview
- Note render time

**Status**: ‚¨ú Not Tested | ‚úÖ Passed | ‚ùå Failed

**Notes**: _________________

---

### Test 9: AC1, AC3, AC4, AC5, AC6 - Completion Summary

**What to test**: Workflow provides complete summary with next steps

**Steps**:

1. Continue from Test 8
2. Observe final summary output

**Expected Result**:

‚úÖ Penny displays:
- Created Artifacts table with file paths
- Template, Schema, and Mock Data (if generated) locations
- Preview summary (purpose, inputs count, output format)
- Next steps: `*test`, `*refine`, `*validate`
- Usage instructions

**Evidence**:

- Screenshot of completion summary

**Status**: ‚¨ú Not Tested | ‚úÖ Passed | ‚ùå Failed

**Notes**: _________________

---

### Test 10: Error Handling - Invalid Name Rejected

**What to test**: Workflow handles invalid inputs gracefully

**Steps**:

1. Start a new `*new` workflow
2. Provide valid purpose
3. Provide valid inputs
4. Try invalid names: `MyPrompt`, `test prompt`, `123-name`

**Expected Result**:

‚úÖ Penny:
- Detects invalid kebab-case format
- Explains the validation error
- Prompts user to try again
- Does not crash or proceed with invalid name

**Evidence**:

- Screenshot of validation error message

**Status**: ‚¨ú Not Tested | ‚úÖ Passed | ‚ùå Failed

**Notes**: _________________

---

## ‚è≥ Not Testable Yet

**AC6 (full API integration)**: Complete API integration for preview
**Reason**: `POST /api/prompt/render` needs server running with template file access
**When**: Can be tested when server and file system are fully integrated

---

## Test Checklist

Copy this checklist to track overall progress:

**Terminal Tests:**

- [x] Test A: Workflow file exists with metadata ‚úÖ
- [x] Test B: Workflow has all 9 steps ‚úÖ
- [x] Test C: Elicitation steps have validation ‚úÖ
- [x] Test D: Steps use stores for data flow ‚úÖ
- [x] Test E: Conditional mock data generation ‚úÖ

**Human Tests:**

- [ ] Test 1: Prompt Purpose Elicitation
- [ ] Test 2: Input Requirements Elicitation
- [ ] Test 3: Prompt Naming with Validation
- [ ] Test 4: Template File Creation
- [ ] Test 5: Schema Generation
- [ ] Test 6: Mock Data Offering
- [ ] Test 7: Mock Data Generation
- [ ] Test 8: Preview Rendered Template
- [ ] Test 9: Completion Summary
- [ ] Test 10: Error Handling

**Overall Status**: üîÑ In Progress (Terminal Tests: 5/5 ‚úÖ | Human Tests: 0/10 pending)

---

## Troubleshooting

### Issue: Agent doesn't activate

**Symptom**: `/poem/agents/penny` doesn't activate Penny
**Solution**:
1. Check slash command exists: `ls .claude/commands/poem/agents/`
2. Ensure `prompt-engineer.md` exists in `packages/poem-core/agents/`
3. Try syncing commands if needed

### Issue: Server not running for API calls

**Symptom**: API calls fail during workflow
**Solution**:
1. Start server: `cd packages/poem-app && npm run dev`
2. Verify: `curl http://localhost:4321/api/health`
3. Check `.env` has `POEM_DEV=true`

### Issue: Files created in wrong location

**Symptom**: Files appear in `poem/prompts/` instead of `prompts/`
**Solution**:
1. Verify `POEM_DEV=true` in `.env`
2. Check `packages/poem-core/` directory exists (triggers dev mode)
3. Restart conversation after changing environment

### Issue: Workflow step skipped

**Symptom**: Expected step doesn't appear
**Solution**:
1. Check previous step's response was valid
2. Verify condition logic in workflow YAML
3. Conditional steps (generate-mock) require specific responses

---

## Test Results Summary

**Date Tested**: _________________

**Tester**: _________________

**Results**:

- Terminal Tests: __ / 5 passed
- Human Tests: __ / 10 passed
- Total: __ / 15 passed

**Issues Found**:

1. _________________
2. _________________

**Sign-off**: ‚úÖ Story accepted | ‚ùå Issues require fixes

---

_Generated by Taylor (SAT Guide Creator) from Story 3.2_
