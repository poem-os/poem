# Storyline Application - POEM Planning Example

**Status**: Planning reference data
**Purpose**: Demonstrate POEM capabilities with storytelling/content generation domain
**Source**: Boy and the Baker project (vOz client)

---

## What This Example Shows

This is a **real-world example** of prompt-driven data transformation:

**INPUT**: Simple narrative transcript (631 words)
**OUTPUT**: Rich storyline structure (21KB JSON with 64 beats, 68 visual concepts)

This demonstrates POEM's potential for:

- Multi-step prompt orchestration
- Complex data transformation pipelines
- Cross-domain prompt engineering (vs SupportSignal's NDIS focus)

---

## Directory Structure

```
storyline/
├── source/                          # Input data
│   ├── transcript.txt              # Original story narrative (631 words)
│   └── storyline-v2.json           # Output structure (21KB)
│
├── prompts/                         # Template prompts (reconstructed)
│   ├── extract-characters.hbs      # Extract cast from narrative
│   ├── define-visual-style.hbs     # Create style guide
│   ├── break-into-beats.hbs        # Segment into narrative beats
│   └── generate-visual-concepts.hbs # Create shot breakdowns per beat
│
├── schemas/                         # Data structure definitions
│   ├── character-schema.json       # Cast member structure
│   └── storyline-output-schema.json # Complete output format
│
└── mappings/                        # Transformation documentation
    └── transcript-to-storyline.json # Multi-step pipeline mapping
```

---

## The Transformation Pipeline

### Step 1: Extract Characters

**Prompt**: `extract-characters.hbs`
**Input**: transcript.txt
**Output**: Cast array with visual profiles, character arcs, symbolism

**Example Output**:

```json
{
  "key": "baker",
  "name": "The Baker",
  "age": "60-63",
  "visualProfile": {
    "build": "Sturdy frame, gently weathered",
    "colorSignature": ["warm ochre", "dusty brown", "cream"],
    "symbolism": "Bread as sacrament; represents sanctuary"
  }
}
```

### Step 2: Define Visual Style

**Prompt**: `define-visual-style.hbs`
**Input**: transcript.txt
**Output**: Style guide with era, influences, color palettes, scene anchors

**Example Output**:

```json
{
  "corePhilosophy": "Hand-drawn warmth with narrative restraint",
  "era": "1930s",
  "visualInfluences": ["Studio Ghibli", "90s RPG storybook art"],
  "colorPalette": {
    "primary": ["soft browns", "warm earth tones", "dusty oranges"]
  }
}
```

### Step 3: Break Into Beats

**Prompt**: `break-into-beats.hbs`
**Input**: transcript.txt + timing data
**Output**: 64 narrative beats with timing, text, scene defaults

**Example Output**:

```json
{
  "id": 1,
  "timing": { "start": "00:05.56", "end": "00:13.36", "duration": 7800 },
  "narrative": {
    "text": "An elderly baker walking to his shop...",
    "speaker": "narrator"
  },
  "beatLevelDefaults": {
    "sceneAnchor": "dusty-street-corner",
    "ambiance": "Warm morning sun, long angled shadows"
  }
}
```

### Step 4: Generate Visual Concepts

**Prompt**: `generate-visual-concepts.hbs`
**Input**: Each beat + cast + style guide
**Output**: 1-4 visual concepts per beat (68 total)

**Example Output**:

```json
{
  "conceptNumber": 1,
  "description": "Baker walks toward shop, morning stillness",
  "shotType": "wide",
  "cameraAngle": "eye-level",
  "mood": "warm, peaceful",
  "characters": ["baker"],
  "purpose": "Establish the peaceful morning routine before disruption"
}
```

---

## Key Insights for POEM

### 1. Multi-Step Orchestration

Unlike SupportSignal's single-prompt workflows, this requires:

- Sequential execution (Step 4 needs outputs from Steps 1-3)
- Context accumulation (each step builds on previous)
- State management across prompts

### 2. Data Source Complexity

**Input data source**: `storyline.transcript` (simple text)
**Intermediate data sources**:

- `storyline.cast` (generated by Step 1)
- `storyline.styleGuide` (generated by Step 2)
- `storyline.beats` (generated by Step 3)
  **Final data source**: `storyline.complete` (all components assembled)

### 3. Template Reusability

The `generate-visual-concepts` template:

- Runs 64 times (once per beat)
- Uses different data each time (current beat context)
- Consistent output format
- This is the "loop/iteration" pattern

### 4. Rich Output Structure

631 words → 21KB structured data:

- 64 beats with precise timing
- 3 characters with detailed profiles
- 68 visual concepts with shot composition
- Complete style guide with color palettes
- Machine-readable format for downstream processing

---

## Comparison: SupportSignal vs Storyline

| Aspect           | SupportSignal (NDIS)                     | Storyline (Content Generation)                   |
| ---------------- | ---------------------------------------- | ------------------------------------------------ |
| **Domain**       | Healthcare/compliance                    | Creative/storytelling                            |
| **Input**        | Incident reports                         | Narrative transcript                             |
| **Output**       | Enhanced narratives, analysis            | Visual production spec                           |
| **Workflow**     | Linear (questions → answers → enhance)   | Pipeline (extract → style → segment → visualize) |
| **Prompts**      | 8 workflow-specific                      | 4 transformation steps                           |
| **Data Sources** | `incident.single`, `incident.collection` | `storyline.transcript`, `storyline.complete`     |
| **Complexity**   | Single-step prompts                      | Multi-step orchestration                         |

---

## What POEM Needs to Support This

1. **Pipeline Orchestration**: Execute prompts in sequence, passing outputs as inputs
2. **Context Management**: Accumulate state across multiple prompt executions
3. **Loop Iteration**: Run same prompt multiple times with different data (per-beat concepts)
4. **Data Source Evolution**: Handle intermediate data sources created during processing
5. **Mock Data Generation**: Generate example beats/characters for testing without full pipeline

---

## Notes

- **Prompts are reconstructed** from analyzing the output structure (we don't have access to original prompts from Boy & Baker development)
- **These are boilerplate/token representations** to illustrate the transformation pattern
- **Real prompts would be more detailed** with specific style guidelines, constraints, examples
- **This is planning reference data** to inform POEM's architecture, not production templates

---

**Last Updated**: 2025-11-20
